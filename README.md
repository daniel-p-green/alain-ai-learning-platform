<div align="center">

  <img src="brand/ALAIN-wordmarks/ALAIN_logo_primary_blue-bg.png" alt="ALAIN logo" width="420" />

  <br/>
  <br/>

  <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT"></a>
  <img src="https://img.shields.io/badge/Teacher-GPT--OSS--20B-4b8" alt="Teacher: GPT-OSS-20B">
  <img src="https://img.shields.io/badge/Providers-Poe_%7C_OpenAI--compatible-795" alt="Providers: Poe | OpenAI-compatible">
  <img src="https://img.shields.io/badge/Mode-Offline_Supported-2aa" alt="Offline Supported">

</div>

# ALAIN ‚Äî Applied Learning AI Notebooks

## The open source IKEA instruction layer for AI models

### Learn AI with AI: pick any model in Hugging Face, Ollama, or LM Studio & get interactive how-to guides. Run locally or in the cloud with gpt-oss.

---

## üöÄ Elevator Pitch

ALAIN is the open-source IKEA instruction layer for AI models. We transform the way developers and researchers learn and experiment with AI models by providing:

- **Instant, Interactive Learning**: Turn any AI model into an interactive learning environment with guided tutorials and hands-on exercises
- **Universal Compatibility**: Works seamlessly with models from Hugging Face, Ollama, and LM Studio
- **Flexible Deployment**: Run locally for privacy or in the cloud for convenience
- **Open Source & Community-Driven**: Built by and for the AI community

Whether you're a researcher testing the latest models or a developer integrating AI into your applications, ALAIN helps you get from model to mastery faster than ever before.

---

## Quick Links

- üéØ [Live Demo](#) (coming soon)
- üé• [3-minute Demo Video](#)
- üìù [Devpost Submission](#)
- üìö [Documentation](#getting-started)
- üí¨ [Join our Community](#community)

### One‚ÄëClick Demo (Judge Fast Path)

- Hosted (Poe): open `/generate` ‚Üí click ‚ÄúUse Example (Hosted)‚Äù ‚Üí preview appears, then open tutorial and run a step.
- Local (Ollama): ensure `ollama serve` and a model is available (`ollama pull gpt-oss:20b`) ‚Üí `/generate` ‚Üí click ‚ÄúUse Example (Local)‚Äù.
- If not configured, a ‚ÄúSetup needed‚Äù callout links you to Settings ‚Üí Environment Status, where quick presets and test buttons get you ready in seconds.

## Features

- **Local/Offline First** - Full functionality without cloud dependencies
- **Multi-Model Support** - Connect to any model with an OpenAI-compatible API
- **Interactive Tutorials** - Step-by-step guides that work with your models
- **Open Standards** - Built on open formats and protocols

---

## Submission Categories (Hackathon)

- Best Local Agent: Offline, identical, safe. ALAIN generates interactive how‚Äëto guides entirely on device with gpt‚Äëoss via Ollama or LM Studio. Same UX as cloud, parameterized runs only, export to Jupyter. Local‚Äëfirst without trade‚Äëoffs.
- For Humanity: Make AI literacy universal. ALAIN lowers barriers with open source, local‚Äëfirst guides that work offline in low‚Äëconnectivity classrooms, clinics, and libraries. No data leaves the device; students learn by doing, not watching.
- Wildcard: Infrastructure for adoption. The missing instruction layer that gets models used, not just released. ALAIN isn‚Äôt another app‚Äîit‚Äôs the instruction layer that turns model cards into runnable, hands‚Äëon lessons across providers.

---

## Judge Fast Path (60‚Äì120s)

Option A ‚Äî Hosted (Poe)
1) Run backend and web (see Quick Start).
2) In the web UI: paste `openai/gpt-oss-20b` ‚Üí Provider: Poe ‚Üí Generate ‚Üí Open Tutorial.
3) From the tutorial page, click "Download Colab Notebook" to export a ready-to-run `.ipynb` (uses backend `/export/colab/:id`).
Note: Streaming is handled via the Next.js API route using SSE. Encore backend streaming is disabled in this MVP.

Option B ‚Äî Strict Offline (Ollama)
1) `ollama pull gpt-oss:20b`
2) One command: from repo root run `npm run dev:offline`
   - Starts backend + web with `OFFLINE_MODE=1`, `TEACHER_PROVIDER=openai-compatible`, and sensible defaults for Ollama.
3) Open http://localhost:3000
4) Paste `openai/gpt-oss-20b` ‚Üí Provider: Local (OpenAI‚Äëcompatible) ‚Üí Generate.
5) Click "Download Colab Notebook" (works offline; no third-party calls in export).
6) Note: Exported notebook includes a Pre‚Äëflight cell that verifies API connectivity before running steps.
Note: For local demos, you may set `DEMO_ALLOW_UNAUTH=1` to bypass auth.

Option C ‚Äî Local (LM Studio)
1) Open LM Studio and enable the Local Server (default `http://localhost:1234/v1`)
2) One command: from repo root run `npm run dev:offline` (or your usual dev flow)
3) Open http://localhost:3000
4) In Generate: select ‚ÄúFrom Local Runtime‚Äù (auto-selected if detected), pick a model (e.g., `llama-3-8b-instruct`) and click Generate
5) Run a step, then click ‚ÄúDownload Colab Notebook‚Äù
6) Note: The ‚ÄúLocal Setup Helper‚Äù appears under the Local model picker with a copyable `ollama pull gpt-oss:20b` command and a Test Connection button.
Notes:
- Streaming is handled via the Next.js API route using SSE; Encore streaming is disabled in this MVP.
- For local demos, you may set `DEMO_ALLOW_UNAUTH=1` to bypass auth.

Option D ‚Äî From Text (Docs ‚Üí Lesson)
1) On the Generate page, click ‚ÄúFrom Text‚Äù.
2) Paste a snippet (e.g., a section from OpenAI docs on Harmony‚Äëstyle prompting).
3) Choose Teacher Provider (Poe or Local), then Generate ‚Üí Preview ‚Üí Export.
Notes:
- This bypasses Hugging Face metadata entirely; great for live copy‚Äëpaste demos.
- Exported notebooks include the Pre‚Äëflight check cell.

Minimal offline cURL (no web UI)
- Enable local demo bypass in backend env: `DEMO_ALLOW_UNAUTH=1`
```bash
curl -s -X POST http://localhost:4000/lessons/generate \
  -H 'Content-Type: application/json' \
  -d '{
    "hfUrl":"openai/gpt-oss-20b",
    "difficulty":"beginner",
    "teacherModel":"GPT-OSS-20B",
    "includeAssessment":true,
    "provider":"openai-compatible"
  }' | jq '.success, .lesson.title'
```

Note: In offline mode we never fetch external metadata; owner/repo is parsed locally and lesson generation runs against your local endpoint. The web header shows an OFFLINE MODE badge when active.

‚Äî

## Why It Matters
- Learners hit walls reading static model cards; they need runnable guidance.
- ALAIN turns model links into hands‚Äëon lessons with assessments, exportable to Colab.
- Local mode removes cost and access barriers (schools, air‚Äëgapped labs, events).

What‚Äôs Novel
- ‚ÄúPaste HF ‚Üí runnable, graded lesson‚Äù with schema validation and auto‚Äërepair.
- Cost‚Äëaware exercises and parameterized execution (no arbitrary code injection).
- True offline: strict metadata‚Äëfree mode + local teacher via OpenAI‚Äëcompatible API.

‚Äî

## How It Works
- Backend parses model ref (no network in OFFLINE_MODE) ‚Üí teacher (gpt‚Äëoss‚Äë20b by default) generates schema‚Äëvalid lesson JSON (with one‚Äëshot repair) ‚Üí UI renders a playable lesson ‚Üí optional Colab export.
- Providers
  - Hosted: Poe (`POE_API_KEY`) with `GPT-OSS-20B` / `GPT-OSS-120B`
  - Local: OpenAI‚Äëcompatible endpoints (Ollama, LM Studio, vLLM) using identical request shape

Concrete references
- Provider aliasing: `poe` vs local
  - alain-ai-learning-platform/backend/execution/providers/aliases.ts:7
  - alain-ai-learning-platform/backend/execution/providers/aliases.ts:20
- Default model and provider
  - alain-ai-learning-platform/backend/execution/spec/lessonSchema.ts:99
  - alain-ai-learning-platform/backend/execution/spec/lessonSchema.ts:100
- Routing guard for 120B ‚Üí Poe
  - alain-ai-learning-platform/backend/execution/teacher.routing.test.ts:10
- Strict offline (no metadata fetch)
  - alain-ai-learning-platform/backend/execution/lesson-generator.ts:153
  - alain-ai-learning-platform/backend/execution/parse-model.ts:12
- OFFLINE badge (web)
  - alain-ai-learning-platform/web/components/OfflineBadge.tsx:1

‚Äî

## Quick Start (5‚Äì10 minutes)

Prerequisites
- Node.js 18+
- Go + Encore CLI (backend)
  - macOS: `brew install encoredev/tap/encore`
  - Linux/Windows: see Encore docs; verify with `encore --version`
- Optional Local: [Ollama](https://ollama.ai) and `ollama pull gpt-oss:20b`

1) Install dependencies
```bash
# From repo root
npm install

# Optional (notebooks/tools)
pip install -r requirements.txt
pip install -r requirements-dev.txt && pre-commit install
```

2) Configure environment
- Web (.env.local): `cp env.web.example web/.env.local`
- Backend (Encore secrets preferred; or local env file):
```bash
encore secret set POE_API_KEY
encore secret set OPENAI_BASE_URL
encore secret set OPENAI_API_KEY
# or for local-only dev
cp env.backend.example backend/.env.local
```

Web env (`web/.env.local`)
- Clerk: `NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY`, `CLERK_SECRET_KEY`
- Hosted: `POE_API_KEY`
- Local: `NEXT_PUBLIC_BACKEND_BASE` (defaults to http://localhost:4000)

Backend env
- Hosted default: `TEACHER_PROVIDER=poe`
- Local default: `TEACHER_PROVIDER=openai-compatible`, set `OPENAI_BASE_URL`, `OPENAI_API_KEY`
- Strict Offline: `OFFLINE_MODE=1` (skip external metadata fetches)
- Optional demo cURL: `DEMO_ALLOW_UNAUTH=1` (local only)

3) Start services
```bash
# Easiest: one command dev modes
npm run dev:offline   # local/offline via Ollama (auto defaults)
# or
npm run dev:hosted    # hosted via Poe (requires POE_API_KEY)

# Manual (if preferred)
# Terminal A ‚Äî Backend (Encore.ts)
# cd backend && encore run    # http://localhost:4000
# Terminal B ‚Äî Web (Next.js)
# cd web && npm run dev       # http://localhost:3000
```

4) Use the app
1) Open http://localhost:3000 and sign in (Clerk)
2) Go to Generate and paste a Hugging Face model (e.g. `meta-llama/Meta-Llama-3.1-8B-Instruct`)
3) Pick Provider: Poe (hosted) or Local (OpenAI‚Äëcompatible)
4) Generate ‚Üí preview ‚Üí Open Tutorial ‚Üí run steps with streaming output
5) Optional: visit Settings ‚Üí Setup Wizard to auto‚Äëswitch between Hosted and Offline modes.

Local (Ollama) cheatsheet
```bash
ollama pull gpt-oss:20b
encore secret set OPENAI_BASE_URL http://localhost:11434/v1
encore secret set OPENAI_API_KEY ollama
```

Local (LM Studio) cheatsheet
```bash
# In LM Studio: enable Local Server (default http://localhost:1234/v1)
encore secret set OPENAI_BASE_URL http://localhost:1234/v1
encore secret set OPENAI_API_KEY lmstudio
```

Notes
- Teacher aliasing: `GPT-OSS-20B` ‚Üí `gpt-oss:20b` for local runs
- 20B needs ‚â•16GB VRAM or Apple Silicon with enough unified memory; CPU offload works but is slow
- Strict Offline: set `OFFLINE_MODE=1` and `TEACHER_PROVIDER=openai-compatible`. Paste owner/repo or full URL; parsing is local.

‚Äî

## Design, Safety, and Cost
- No arbitrary code execution; lessons run parameterized calls only.
- Secrets via Encore; env examples provided.
- Linter: `scripts/notebook_linter.py` checks seeds, pins, secrets, evaluation, cost logs.
- Streaming: implemented at Next.js layer with retry fallback.

‚Äî

## Category Fit (Hackathon)
- Best Local Agent: useful agentic generation with no internet access.
- For Humanity: reduces cost/privacy barriers to advanced AI learning.
- Most Useful Fine‚ÄëTune: roadmap includes targeted educational fine‚Äëtunes.

Roadmap
- Reasoning traces UI (opt‚Äëin)
- Stronger assessment bank and rubric validation
- One‚Äëclick Colab export with data stubs

‚Äî

## Project Structure
```
alain-ai-learning-platform/
‚îú‚îÄ‚îÄ backend/                 # Encore.ts APIs (execution, lessons, export)
‚îÇ   ‚îú‚îÄ‚îÄ execution/           # Provider routing, teacher, streaming
‚îÇ   ‚îú‚îÄ‚îÄ tutorials/           # CRUD, import, versioning
‚îÇ   ‚îî‚îÄ‚îÄ export/              # Colab notebook export
‚îú‚îÄ‚îÄ web/                     # Next.js app (Clerk auth, UI)
‚îÇ   ‚îî‚îÄ‚îÄ app/                 # Generate page, tutorial player, settings
‚îú‚îÄ‚îÄ prompts/                 # ALAIN‚ÄëKit prompts (Harmony format)
‚îú‚îÄ‚îÄ POE_INTEGRATION_GUIDE.md # Provider usage and examples
‚îú‚îÄ‚îÄ HACKATHON_README.md      # Hackathon context & architecture
‚îî‚îÄ‚îÄ env-config-example.txt   # Copy to .env.local for web
```

Docs & Tools
- Notebook Linter: `scripts/notebook_linter.py`

### Onboarding + Settings (Web)
- New self-contained module lives at `web/features/onboarding-settings/`.
- Routes:
  - `/onboarding` ‚Äî 5-step wizard. Keys never leave the device.
  - `/settings` ‚Äî tabs: Account, Providers, Models, Appearance, Onboarding & Demo, Advanced.
- Reset onboarding: Settings ‚Üí Onboarding & Demo ‚Üí Reset onboarding.
- LocalStorage keys: `alain.onboarding.version`, `alain.onboarding.completed`, `alain.providers`, `alain.models`, `alain.ui.theme`.
- Module docs: `web/features/onboarding-settings/README_OnboardingSettings.md`.
- Best Practices: `docs/notebooks/notebook-best-practices.md`
- Author Checklist: `docs/notebooks/notebook-quality-checklist.md`
- Teaching Template: `docs/templates/teaching_template.ipynb`
- More: `docs/notebooks/*`, `docs/gpt-oss/*`

‚Äî

## Phases Orchestration (Thin Web Stub)
- Endpoint: `POST /api/phases`
  - Body: `{ phase: 'Research'|'Design'|'Develop'|'Validate', provider: 'poe'|'openai-compatible', model: 'GPT-OSS-20B'|..., input?: any }`
  - Behavior: Loads the Harmony prompt for the requested phase from `prompts/alain-kit/<phase>.harmony.txt`, composes a simple user message with your `input`, and calls the configured provider via our existing provider abstraction (Poe or OpenAI‚Äëcompatible). Returns `{ ok, content }`.
  - File: `web/app/api/phases/route.ts:1`
- UI: visit `/phases` for a minimal four‚Äëbutton page that hits the API and shows activity.
  - File: `web/app/phases/page.tsx:1`

Develop/Validate automation
- If `phase` is `Develop` or `Validate`, the API attempts to parse the model output as JSON (strips code fences), then:
  - Writes lesson JSON to `lessons/<provider>/<model>/lesson.json`
  - If `autoRender` (default true): renders notebook to `notebooks/<provider>/<model>/lesson.ipynb`
  - Runs a smoke check and writes `reports/<provider>/<model>/validation.json`
  - The API response includes `artifacts` with file paths and (if available) the parsed smoke report.

Environment for providers (web):
- Poe hosted: set `POE_API_KEY`
- OpenAI‚Äëcompatible (local/cloud): set `OPENAI_BASE_URL`, `OPENAI_API_KEY`

‚Äî

## Colab Link Builder (Optional)
- Set `NEXT_PUBLIC_GITHUB_REPO` to `org/repo` and optional `NEXT_PUBLIC_GITHUB_BRANCH` (default `main`).
- The tutorial page will show an ‚ÄúOpen in Colab‚Äù link that assumes notebooks are published under:
  - `notebooks/<provider>/<owner>/<repo>/lesson.ipynb`
- File: `web/app/tutorial/[id]/page.tsx:1`

‚Äî

## Troubleshooting
- Backend won‚Äôt start: install Encore CLI and run from `backend/` (`encore run`)
- Unauthorized on web: set Clerk keys in `.env.local`, restart web
- Provider errors: set `POE_API_KEY` (hosted) or `OPENAI_BASE_URL`/`OPENAI_API_KEY` (local)
- Local is slow: reduce tokens, or try hosted Poe
- Streaming: SSE via Next.js; retries once; non‚Äëstreaming fallback succeeds
- Offline mode: if `OFFLINE_MODE=1`, ensure `TEACHER_PROVIDER=openai-compatible` and local endpoint running

‚Äî

## License
MIT

Credits
- GPT‚ÄëOSS by OpenAI
- Poe by Quora
- Encore, Clerk, Next.js, Tailwind
