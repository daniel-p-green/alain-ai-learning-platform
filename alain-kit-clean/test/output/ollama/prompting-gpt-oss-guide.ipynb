{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "title": "Prompting GPT-OSS & Getting Started",
    "authors": [
      {
        "name": "OpenAI Assistant",
        "affiliation": "OpenAI"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompting GPT-OSS & Getting Started\n",
        "\n",
        "Welcome to this beginner‑friendly notebook. We’ll walk through:\n",
        "\n",
        "1. What GPT‑OSS is and why it matters.\n",
        "2. How to structure a prompt and use formatting.\n",
        "3. Your first prompt example.\n",
        "4. Common pitfalls and how to avoid them.\n",
        "5. Best practices for beginners.\n",
        "6. Interactive exercises so you can practice right away.\n",
        "\n",
        "*This notebook uses the `transformers` library and a small open‑source GPT model (distilgpt2) so you don’t need an API key.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is GPT‑OSS and Why Use It?\n",
        "\n",
        "GPT‑OSS refers to **open‑source GPT‑style language models** such as GPT‑Neo, GPT‑J, or the distilled version of GPT‑2 (distilgpt2). They:\n",
        "\n",
        "- **Run locally** or on a GPU/CPU you control.\n",
        "- **Avoid usage limits** and costs that come with commercial APIs.\n",
        "- **Give you full control** over the model weights and training data.\n",
        "- **Allow experimentation** with new prompt strategies and fine‑tuning.\n",
        "\n",
        "For absolute beginners, starting with a lightweight model like `distilgpt2` is great because it is quick to download, runs on a CPU, and still demonstrates the core prompt‑engineering concepts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Prompt Structure and Formatting\n",
        "\n",
        "A prompt is simply a text string you give to the model. Good prompts:\n",
        "\n",
        "1. **Start with an instruction** or a question.\n",
        "2. **Add context** if needed (e.g., a short story background).\n",
        "3. **Use delimiters** (quotes, brackets) to separate parts.\n",
        "4. **Keep it concise** – the model performs best with clear, focused prompts.\n",
        "\n",
        "Example formatting:\n",
        "\n",
        "- **Instruction**: \"Write a short poem.\"\n",
        "- **Context** (optional): \"The poem is about autumn leaves.\"\n",
        "- **Delimiter**: Use line breaks or a clear separator.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Building a simple prompt string\n",
        "instruction = \"Write a short poem.\"\n",
        "context = \"The poem is about autumn leaves.\"\n",
        "\n",
        "prompt = f\"{instruction}\\n\\n{context}\\n\"\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting Started with Your First Prompts\n",
        "\n",
        "We’ll use the `transformers` pipeline to load `distilgpt2` and generate text from our prompt.\n",
        "If you don’t have `transformers` installed yet, run `pip install transformers`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Install transformers if needed\n",
        "# !pip install transformers -q\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a lightweight GPT model\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "# Generate a response for our prompt\n",
        "generated = generator(prompt, max_length=60, num_return_sequences=1)[0]['generated_text']\n",
        "print(\"Generated text:\\n\", generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common Pitfalls and How to Avoid Them\n",
        "\n",
        "- **Overly long prompts**: The model’s context window is limited. Keep prompts under ~1024 tokens for `distilgpt2`.\n",
        "- **Ambiguous instructions**: The model may produce irrelevant output. Use precise verbs and nouns.\n",
        "- **No delimiters**: Mixing instruction and context can confuse the model. Use line breaks or separators.\n",
        "- **Ignoring temperature**: Default `temperature=1.0` can produce noisy text. Lower it (e.g., 0.7) for more deterministic output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example of a noisy prompt (high temperature)\n",
        "bad_prompt = \"Explain the meaning of life.\"\n",
        "bad_output = generator(bad_prompt, max_length=50, temperature=1.5, num_return_sequences=1)[0]['generated_text']\n",
        "print(\"Bad output (high temperature):\\n\", bad_output)\n",
        "\n",
        "# A cleaner prompt with lower temperature\n",
        "good_prompt = \"Explain the meaning of life in 3 short sentences.\"\n",
        "good_output = generator(good_prompt, max_length=50, temperature=0.7, num_return_sequences=1)[0]['generated_text']\n",
        "print(\"Good output (lower temperature):\\n\", good_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices for Beginners\n",
        "\n",
        "1. **Start simple**: Use short prompts and inspect the output.\n",
        "2. **Iterate**: Slightly tweak wording or add context to see changes.\n",
        "3. **Check token limits**: `distilgpt2` can handle ~1024 tokens.\n",
        "4. **Use temperature and top_k**: Control creativity vs. coherence.\n",
        "5. **Save and compare**: Keep a notebook of prompts that work well.\n",
        "6. **Leverage formatting**: Newlines, bullet points, and quotes help guide the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Examples & Exercises\n",
        "\n",
        "Below is an interactive cell where you can type your own prompt. The model will generate a response. Try different styles, instructions, or contexts to see how the output changes.\n",
        "\n",
        "**Exercise 1**: Prompt the model to write a short joke.\n",
        "**Exercise 2**: Prompt the model to give a 2‑sentence summary of a news headline.\n",
        "\n",
        "Feel free to experiment and compare results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Interactive prompt example\n",
        "user_prompt = input(\"\\nEnter your prompt: \")\n",
        "interactive_output = generator(user_prompt, max_length=80, temperature=0.8, num_return_sequences=1)[0]['generated_text']\n",
        "print(\"\\nGenerated response:\\n\", interactive_output)"
      ]
    }
  ]
}