{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2a40ff73",
      "metadata": {},
      "source": [
        "# Prompting GPT-OSS & Getting Started\n",
        "\n",
        "A quick guide for beginners on how to talk to the open‑source GPT models (GPT‑OSS)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f67f577d",
      "metadata": {},
      "source": [
        "## What is GPT‑OSS and why use it?\n",
        "\n",
        "- **GPT‑OSS** stands for *Open‑Source Generative Pre‑trained Transformers* – community‑maintained models that behave like OpenAI’s ChatGPT but can be run locally or on any cloud.\n",
        "- **Benefits**:\n",
        "  - No vendor lock‑in; you own the weights.\n",
        "  - Full control over privacy and data.\n",
        "  - Often cheaper at scale because you pay only for compute.\n",
        "  - Ability to fine‑tune or extend the model for domain‑specific tasks.\n",
        "\n",
        "These models are ideal for developers, researchers, and hobbyists who want a powerful LLM without the restrictions of commercial APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae8bc483",
      "metadata": {},
      "source": [
        "## Basic prompt structure and formatting\n",
        "\n",
        "1. **System message** – sets the overall behavior (e.g., \"You are a helpful assistant.\")\n",
        "2. **User message** – the actual question or instruction.\n",
        "3. **Assistant response** – what the model returns.\n",
        "\n",
        "### Example format (JSON for many APIs)\n",
        "```json\n",
        "{\n",
        "  \"messages\": [\n",
        "    {\"role\": \"system\", \"content\": \"You are a concise tech writer.\"},\n",
        "    {\"role\": \"user\",   \"content\": \"Explain GPT‑OSS in two sentences.\"}\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "**Tips**:\n",
        "- Keep instructions clear and short.\n",
        "- Use bullet points or numbered lists for multi‑step tasks.\n",
        "- Add delimiters (e.g., triple backticks) when you want the model to treat text as code or data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2cdcd4",
      "metadata": {},
      "source": [
        "## Getting started with your first prompts\n",
        "\n",
        "Below is a minimal Python snippet that loads a GPT‑OSS model with the `transformers` library and runs a prompt.\n",
        "\n",
        "```python\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load a lightweight open‑source model (e.g., Llama‑2‑7B‑Chat)\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\"\n",
        ")\n",
        "\n",
        "def ask_gpt_oss(prompt, system=\"You are a helpful assistant.\"):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\",   \"content\": prompt}\n",
        "    ]\n",
        "    # Convert messages to a single string the model expects\n",
        "    full_prompt = \"\\n\\n\".join([m[\"content\"] for m in messages])\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=150, do_sample=True)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # Remove the original prompt from the output\n",
        "    return response[len(full_prompt):].strip()\n",
        "\n",
        "# Example usage\n",
        "print(ask_gpt_oss(\"Explain the benefits of using GPT‑OSS.\") )\n",
        "```\n",
        "\n",
        "Run the cell, and you should see a short answer generated by the model. Adjust `max_new_tokens`, `temperature`, or the system message to experiment with different behaviours."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
