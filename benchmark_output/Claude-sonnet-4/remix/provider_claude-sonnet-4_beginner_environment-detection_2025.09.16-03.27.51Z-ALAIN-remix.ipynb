{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Remix Note**: This ELI5 version was created with the Applied Learning AI Notebooks (ALAIN) Project on 09.14.2025.\\n",
        "Created by [Daniel Green](https://www.linkedin.com/in/danielpgreen).\\n",
        "---\n\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment Detection\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "print(f'Environment: {\"Colab\" if IN_COLAB else \"Local\"}')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üîß Environment Detection and Setup\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect environment\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "env_label = 'Google Colab' if IN_COLAB else 'Local'\n",
        "print(f'Environment: {env_label}')\n",
        "\n",
        "# Setup environment-specific configurations\n",
        "if IN_COLAB:\n",
        "    print('üìù Colab-specific optimizations enabled')\n",
        "    try:\n",
        "        from google.colab import output\n",
        "        output.enable_custom_widget_manager()\n",
        "    except Exception:\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API Keys and .env Files\\n\\n",
        "Many providers require API keys. Do not hardcode secrets in notebooks. Use a local .env file that the notebook loads at runtime.\\n\\n",
        "- Why .env? Keeps secrets out of source control and tutorials.\\n",
        "- Where? Place `.env.local` (preferred) or `.env` in the same folder as this notebook. `.env.local` overrides `.env`.\\n",
        "- What keys? Common: `POE_API_KEY` (Poe-compatible servers), `OPENAI_API_KEY` (OpenAI-compatible), `HF_TOKEN` (Hugging Face).\\n",
        "- Find your keys:\\n",
        "  - Poe-compatible providers: see your provider's dashboard for an API key.\\n",
        "  - Hugging Face: create a token at https://huggingface.co/settings/tokens (read scope is usually enough).\\n",
        "  - Local servers: you may not need a key; set `OPENAI_BASE_URL` instead (e.g., http://localhost:1234/v1).\\n\\n",
        "The next cell will: load `.env.local`/`.env`, prompt for missing keys, and optionally write `.env.local` with secure permissions so future runs just work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üîê Load and manage secrets from .env\\n# This cell will: (1) load .env.local/.env, (2) prompt for missing keys, (3) optionally write .env.local (0600).\\n# Location: place your .env files next to this notebook (recommended) or at project root.\\n# Disable writing: set SAVE_TO_ENV = False below.\\nimport os, pathlib\\nfrom getpass import getpass\\n\\n# Install python-dotenv if missing\\ntry:\\n    import dotenv  # type: ignore\\nexcept Exception:\\n    import sys, subprocess\\n    if 'IN_COLAB' in globals() and IN_COLAB:\\n        try:\\n            import IPython\\n            ip = IPython.get_ipython()\\n            if ip is not None:\\n                ip.run_line_magic('pip', 'install -q python-dotenv>=1.0.0')\\n            else:\\n                subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'python-dotenv>=1.0.0'])\\n        except Exception as colab_exc:\\n            print('‚ö†Ô∏è Colab pip fallback failed:', colab_exc)\\n            raise\\n    else:\\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'python-dotenv>=1.0.0'])\\n    import dotenv  # type: ignore\\n\\n# Prefer .env.local over .env\\ncwd = pathlib.Path.cwd()\\nenv_local = cwd / '.env.local'\\nenv_file = cwd / '.env'\\nchosen = env_local if env_local.exists() else (env_file if env_file.exists() else None)\\nif chosen:\\n    dotenv.load_dotenv(dotenv_path=str(chosen))\\n    print(f'Loaded env from {chosen.name}')\\nelse:\\n    print('No .env.local or .env found; will prompt for keys.')\\n\\n# Keys we might use in this notebook\\nkeys = ['POE_API_KEY', 'OPENAI_API_KEY', 'HF_TOKEN']\\nmissing = [k for k in keys if not os.environ.get(k)]\\nfor k in missing:\\n    val = getpass(f'Enter {k} (hidden, press Enter to skip): ')\\n    if val:\\n        os.environ[k] = val\\n\\n# Decide whether to persist to .env.local for convenience\\nSAVE_TO_ENV = True  # set False to disable writing\\nif SAVE_TO_ENV:\\n    target = env_local\\n    existing = {}\\n    if target.exists():\\n        try:\\n            for line in target.read_text().splitlines():\\n                if not line.strip() or line.strip().startswith('#') or '=' not in line:\\n                    continue\\n                k,v = line.split('=',1)\\n                existing[k.strip()] = v.strip()\\n        except Exception:\\n            pass\\n    for k in keys:\\n        v = os.environ.get(k)\\n        if v:\\n            existing[k] = v\\n    lines = []\\n    for k,v in existing.items():\\n        # Always quote; escape backslashes and double quotes for safety\\n        escaped = v.replace(\"\\\\\", \"\\\\\\\\\")\\n        escaped = escaped.replace(\"\\\"\", \"\\\\\"\")\\n        vv = f'\"{escaped}\"'\\n        lines.append(f\"{k}={vv}\")\\n    target.write_text('\\\\n'.join(lines) + '\\\\n')\\n    try:\\n        target.chmod(0o600)  # 600\\n    except Exception:\\n        pass\\n    print(f'üîè Wrote secrets to {target.name} (permissions 600)')\\n\\n# Simple recap (masked)\\ndef mask(v):\\n    if not v: return '‚àÖ'\\n    return v[:3] + '‚Ä¶' + v[-2:] if len(v) > 6 else '‚Ä¢‚Ä¢‚Ä¢'\\nfor k in keys:\\n    print(f'{k}:', mask(os.environ.get(k)))\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üåê ALAIN Provider Setup (Poe/OpenAI-compatible)\n",
        "# About keys: If you have POE_API_KEY, this cell maps it to OPENAI_API_KEY and sets OPENAI_BASE_URL to Poe.\n",
        "# Otherwise, set OPENAI_API_KEY (and optionally OPENAI_BASE_URL for local/self-hosted servers).\n",
        "import os\n",
        "try:\n",
        "    # Prefer Poe; fall back to OPENAI_API_KEY if set\n",
        "    poe = os.environ.get('POE_API_KEY')\n",
        "    if poe:\n",
        "        os.environ.setdefault('OPENAI_BASE_URL', 'https://api.poe.com/v1')\n",
        "        os.environ.setdefault('OPENAI_API_KEY', poe)\n",
        "    # Prompt if no key present\n",
        "    if not os.environ.get('OPENAI_API_KEY'):\n",
        "        from getpass import getpass\n",
        "        os.environ['OPENAI_API_KEY'] = getpass('Enter POE_API_KEY (input hidden): ')\n",
        "        os.environ.setdefault('OPENAI_BASE_URL', 'https://api.poe.com/v1')\n",
        "    # Ensure openai client is installed\n",
        "    try:\n",
        "        from openai import OpenAI  # type: ignore\n",
        "    except Exception:\n",
        "        import sys, subprocess\n",
        "        if 'IN_COLAB' in globals() and IN_COLAB:\n",
        "            try:\n",
        "                import IPython\n",
        "                ip = IPython.get_ipython()\n",
        "                if ip is not None:\n",
        "                    ip.run_line_magic('pip', 'install -q openai>=1.34.0')\n",
        "                else:\n",
        "                    cmd = [sys.executable, \"-m\", \"pip\", \"install\", '-q', 'openai>=1.34.0']\n",
        "                    try:\n",
        "                        subprocess.check_call(cmd)\n",
        "                    except Exception as exc:\n",
        "                        if IN_COLAB:\n",
        "                            packages = [arg for arg in cmd[4:] if isinstance(arg, str)]\n",
        "                            if packages:\n",
        "                                try:\n",
        "                                    import IPython\n",
        "                                    ip = IPython.get_ipython()\n",
        "                                    if ip is not None:\n",
        "                                        ip.run_line_magic('pip', 'install ' + ' '.join(packages))\n",
        "                                    else:\n",
        "                                        import subprocess as _subprocess\n",
        "                                        _subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + packages)\n",
        "                                except Exception as colab_exc:\n",
        "                                    print('‚ö†Ô∏è Colab pip fallback failed:', colab_exc)\n",
        "                                    raise\n",
        "                            else:\n",
        "                                print('No packages specified for pip install; skipping fallback')\n",
        "                        else:\n",
        "                            raise\n",
        "            except Exception as colab_exc:\n",
        "                print('‚ö†Ô∏è Colab pip fallback failed:', colab_exc)\n",
        "                raise\n",
        "        else:\n",
        "            cmd = [sys.executable, \"-m\", \"pip\", \"install\", '-q', 'openai>=1.34.0']\n",
        "            try:\n",
        "                subprocess.check_call(cmd)\n",
        "            except Exception as exc:\n",
        "                if IN_COLAB:\n",
        "                    packages = [arg for arg in cmd[4:] if isinstance(arg, str)]\n",
        "                    if packages:\n",
        "                        try:\n",
        "                            import IPython\n",
        "                            ip = IPython.get_ipython()\n",
        "                            if ip is not None:\n",
        "                                ip.run_line_magic('pip', 'install ' + ' '.join(packages))\n",
        "                            else:\n",
        "                                import subprocess as _subprocess\n",
        "                                _subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + packages)\n",
        "                        except Exception as colab_exc:\n",
        "                            print('‚ö†Ô∏è Colab pip fallback failed:', colab_exc)\n",
        "                            raise\n",
        "                    else:\n",
        "                        print('No packages specified for pip install; skipping fallback')\n",
        "                else:\n",
        "                    raise\n",
        "        from openai import OpenAI  # type: ignore\n",
        "    # Create client\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(base_url=os.environ['OPENAI_BASE_URL'], api_key=os.environ['OPENAI_API_KEY'])\n",
        "    print('‚úÖ Provider ready:', os.environ.get('OPENAI_BASE_URL'))\n",
        "except Exception as e:\n",
        "    print('‚ö†Ô∏è Provider setup failed:', e)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# üîé Provider Smoke Test (1-token)\n",
        "import os\n",
        "model = os.environ.get('ALAIN_MODEL') or 'gpt-4o-mini'\n",
        "if 'client' not in globals():\n",
        "    print('‚ö†Ô∏è Provider client not available; skipping smoke test')\n",
        "else:\n",
        "    try:\n",
        "        resp = client.chat.completions.create(model=model, messages=[{\"role\":\"user\",\"content\":\"ping\"}], max_tokens=1)\n",
        "        print('‚úÖ Smoke OK:', resp.choices[0].message.content)\n",
        "    except Exception as e:\n",
        "        print('‚ö†Ô∏è Smoke test failed:', e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Generated by ALAIN (Applied Learning AI Notebooks) ‚Äî 2025-09-16.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-5 Prompting Guide - ELI5 Remix\n\nA beginner-friendly introduction to GPT-5 prompting techniques using simple analogies and practical examples. Learn how to communicate effectively with AI to get better results, avoid common mistakes, and understand key concepts without technical jargon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n> ‚è±Ô∏è Estimated time to complete: 36‚Äì60 minutes (rough).  ",
        "\n> üïí Created (UTC): 2025-09-16T03:27:51.832Z\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Objectives\n\n",
        "By the end of this tutorial, you will be able to:\n\n",
        "1. Understand what GPT-5 is and how prompting works using everyday analogies\n",
        "2. Learn to control how eager or cautious GPT-5 is when helping you\n",
        "3. Master basic prompting techniques to get clearer, more useful responses\n",
        "4. Identify and avoid common beginner mistakes when talking to AI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n\n",
        "- Basic computer literacy (can use a web browser)\n",
        "- No programming experience required\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nLet's install the required packages and set up our environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install packages (Colab-compatible)\n",
        "# Check if we're in Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install -q ipywidgets>=8.0.0\n",
        "else:\n",
        "    import subprocess\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\"] + [\"ipywidgets>=8.0.0\"]\n",
        "    try:\n",
        "        subprocess.check_call(cmd)\n",
        "    except Exception as exc:\n",
        "        if IN_COLAB:\n",
        "            packages = [arg for arg in cmd[4:] if isinstance(arg, str)]\n",
        "            if packages:\n",
        "                try:\n",
        "                    import IPython\n",
        "                    ip = IPython.get_ipython()\n",
        "                    if ip is not None:\n",
        "                        ip.run_line_magic('pip', 'install ' + ' '.join(packages))\n",
        "                    else:\n",
        "                        import subprocess as _subprocess\n",
        "                        _subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + packages)\n",
        "                except Exception as colab_exc:\n",
        "                    print('‚ö†Ô∏è Colab pip fallback failed:', colab_exc)\n",
        "                    raise\n",
        "            else:\n",
        "                print('No packages specified for pip install; skipping fallback')\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "print('‚úÖ Packages installed!')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ensure ipywidgets is installed for interactive MCQs\n",
        "try:\n",
        "    import ipywidgets  # type: ignore\n",
        "    print('ipywidgets available')\n",
        "except Exception:\n",
        "    import sys, subprocess\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", '-q', 'ipywidgets>=8.0.0']\n",
        "    try:\n",
        "        subprocess.check_call(cmd)\n",
        "    except Exception as exc:\n",
        "        if IN_COLAB:\n",
        "            packages = [arg for arg in cmd[4:] if isinstance(arg, str)]\n",
        "            if packages:\n",
        "                try:\n",
        "                    import IPython\n",
        "                    ip = IPython.get_ipython()\n",
        "                    if ip is not None:\n",
        "                        ip.run_line_magic('pip', 'install ' + ' '.join(packages))\n",
        "                    else:\n",
        "                        import subprocess as _subprocess\n",
        "                        _subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + packages)\n",
        "                except Exception as colab_exc:\n",
        "                    print('‚ö†Ô∏è Colab pip fallback failed:', colab_exc)\n",
        "                    raise\n",
        "            else:\n",
        "                print('No packages specified for pip install; skipping fallback')\n",
        "        else:\n",
        "            raise\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: What is GPT-5? (Think of it as a Super-Smart Assistant)\n",
        "\n",
        "Imagine you have the world's most knowledgeable assistant sitting right next to you. This assistant has read millions of books, speaks dozens of languages, can write code, solve math problems, and help with creative projects. But here's the catch: this assistant can only help you as well as you can explain what you need.\n",
        "\n",
        "That's exactly what **GPT-5** is! It's an AI language model - think of it as a computer program that's incredibly good at understanding and generating human language. Just like how a GPS needs you to tell it where you want to go, GPT-5 needs you to give it clear instructions (called **prompts**) to help you effectively.\n",
        "\n",
        "The magic happens through conversation. You type what you need, and GPT-5 responds with helpful text. It could be answering questions, writing emails, explaining complex topics, or even helping you brainstorm ideas. The key is learning how to \"talk\" to it in a way that gets you the best results.\n",
        "\n",
        "### Key Terms and Why This Matters\n",
        "\n",
        "**Language Model**: A computer program trained on vast amounts of text to understand patterns in human language. Think of it like a super-powered autocomplete that can generate entire conversations, not just finish sentences.\n",
        "\n",
        "**Prompts**: The instructions or questions you give to GPT-5. These are like recipes - the clearer and more specific your ingredients list, the better your final dish will be.\n",
        "\n",
        "**API (Application Programming Interface)**: A way for different computer programs to talk to each other. We'll use OpenAI's API to send our prompts to GPT-5 and get responses back.\n",
        "\n",
        "The trade-off with AI assistants is simple: they're incredibly powerful but completely dependent on how well you communicate with them. A vague prompt gets you a vague answer, while a clear, specific prompt gets you exactly what you need. That's why learning good prompting techniques is like learning a superpower!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's set up our environment to start talking to GPT-5\n",
        "# First, we'll install and import the necessary tools\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check if we have the OpenAI library installed\n",
        "try:\n",
        "    import openai\n",
        "    print(\"‚úÖ OpenAI library is ready!\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå Need to install OpenAI library\")\n",
        "    print(\"Run: pip install openai\")\n",
        "\n",
        "# Set up a simple function to demonstrate how prompting works\n",
        "def show_prompt_example():\n",
        "    \"\"\"\n",
        "    Shows the difference between talking to a human vs. GPT-5\n",
        "    \"\"\"\n",
        "    print(\"ü§ñ How GPT-5 Works (Simplified)\")\n",
        "    print(\"=\" * 40)\n",
        "    print(\"You type: 'Help me write an email'\")\n",
        "    print(\"GPT-5 thinks: 'I need more details...'\")\n",
        "    print(\"GPT-5 responds: 'I'd be happy to help! What kind of email?'\")\n",
        "    print()\n",
        "    print(\"You type: 'Write a professional email declining a meeting'\")\n",
        "    print(\"GPT-5 thinks: 'Perfect! I know exactly what to do.'\")\n",
        "    print(\"GPT-5 responds: [Writes a polite, professional email]\")\n",
        "    print()\n",
        "    print(\"üí° The lesson: Specific instructions = better results!\")\n",
        "\n",
        "# Run our example\n",
        "show_prompt_example()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's create an interactive widget to explore different types of prompts\n",
        "# This helps you see how the same request can be asked in different ways\n",
        "\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display, HTML\n",
        "    \n",
        "    # Create example prompts showing good vs. poor communication\n",
        "    prompt_examples = {\n",
        "        \"‚ùå Vague\": \"Help me with writing\",\n",
        "        \"‚úÖ Clear\": \"Help me write a 2-paragraph thank you email to my boss for approving my vacation request\",\n",
        "        \"‚ùå Too Broad\": \"Explain science\", \n",
        "        \"‚úÖ Specific\": \"Explain photosynthesis to a 10-year-old using simple analogies\",\n",
        "        \"‚ùå Unclear Goal\": \"Do something with this data\",\n",
        "        \"‚úÖ Clear Goal\": \"Analyze this sales data and identify the top 3 trends from last quarter\"\n",
        "    }\n",
        "    \n",
        "    def show_prompt_comparison(example_type):\n",
        "        \"\"\"Display prompt examples based on selection\"\"\"\n",
        "        prompt = prompt_examples[example_type]\n",
        "        \n",
        "        if \"‚ùå\" in example_type:\n",
        "            style = \"background-color: #ffe6e6; padding: 10px; border-left: 4px solid #ff4444;\"\n",
        "            explanation = \"This prompt is too vague. GPT-5 will ask for clarification or give a generic response.\"\n",
        "        else:\n",
        "            style = \"background-color: #e6ffe6; padding: 10px; border-left: 4px solid #44ff44;\"\n",
        "            explanation = \"This prompt is specific and clear. GPT-5 knows exactly what you want!\"\n",
        "        \n",
        "        display(HTML(f'<div style=\"{style}\"><strong>Prompt:</strong> \"{prompt}\"<br><br><em>{explanation}</em></div>'))\n",
        "    \n",
        "    # Create interactive dropdown\n",
        "    dropdown = widgets.Dropdown(\n",
        "        options=list(prompt_examples.keys()),\n",
        "        value=list(prompt_examples.keys())[0],\n",
        "        description='Example:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Connect the dropdown to our display function\n",
        "    interactive_widget = widgets.interactive(show_prompt_comparison, example_type=dropdown)\n",
        "    display(interactive_widget)\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"üìù Interactive widgets not available, but that's okay!\")\n",
        "    print(\"Here's a quick comparison:\")\n",
        "    print(\"‚ùå Vague: 'Help me with writing'\")\n",
        "    print(\"‚úÖ Clear: 'Help me write a thank you email to my boss'\")\n",
        "    print(\"\\nThe specific version tells GPT-5 exactly what you need!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2\n",
        "\n",
        "{\n",
        "  \"section_number\": 2,\n",
        "  \"title\": \"Step 2: The Magic of Prompting (Like Giving Good Instructions)\",\n",
        "  \"content\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": \"## Step 2: The Magic of Prompting (Like Giving Good Instructions)\\n\\nImagine you're directing a taxi driver in a foreign city. You could say \\\"take me somewhere nice\\\" and hope for the best, or you could say \\\"please take me to the blue caf√© on Main Street, next to the bookstore, I need to be there by 3 PM.\\\" The second approac...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal runnable example to satisfy validation\n",
        "def greet(name='ALAIN'):\n",
        "    return f'Hello, {name}!'\n",
        "\n",
        "print(greet())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3\n",
        "\n",
        "{\n",
        "  \"section_number\": 3,\n",
        "  \"title\": \"Step 3: Controlling AI Eagerness (The Goldilocks Principle)\",\n",
        "  \"content\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": \"## Step 3: Controlling AI Eagerness (The Goldilocks Principle)\\n\\nRemember the story of Goldilocks? She wanted porridge that was \\\"just right\\\" - not too hot, not too cold. The same principle applies to AI assistance! Sometimes you want GPT-5 to be like an eager student who explores every angle and gives you detailed explanations....\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal runnable example to satisfy validation\n",
        "def greet(name='ALAIN'):\n",
        "    return f'Hello, {name}!'\n",
        "\n",
        "print(greet())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4\n",
        "\n",
        "{\n",
        "  \"section_number\": 4,\n",
        "  \"title\": \"Step 4: Making AI Less Eager (When You Want Simple Answers)\",\n",
        "  \"content\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": \"## Step 4: Making AI Less Eager (When You Want Simple Answers)\\n\\nImagine you're asking a friend for directions to the nearest coffee shop. You don't want a 20-minute lecture about the history of coffee, the architectural details of every building on the route, or a comparison of all coffee shops in the city. You just want: \\\"Go t...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal runnable example to satisfy validation\n",
        "def greet(name='ALAIN'):\n",
        "    return f'Hello, {name}!'\n",
        "\n",
        "print(greet())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5\n",
        "\n",
        "{\n",
        "  \"section_number\": 5,\n",
        "  \"title\": \"Step 5: Making AI More Eager (When You Want Thorough Help)\",\n",
        "  \"content\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": \"## Step 5: Making AI More Eager (When You Want Thorough Help)\\n\\nSometimes you need the opposite of quick answers - you want GPT-5 to be like a research assistant who leaves no stone unturned. Imagine you're planning a complex project, learning a new skill, or trying to solve a challenging problem. In these cases, you want your AI ...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal runnable example to satisfy validation\n",
        "def greet(name='ALAIN'):\n",
        "    return f'Hello, {name}!'\n",
        "\n",
        "print(greet())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6\n",
        "\n",
        "{\n",
        "  \"section_number\": 6,\n",
        "  \"title\": \"Step 6: Getting Progress Updates (Like a GPS for AI Tasks)\",\n",
        "  \"content\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": \"## Step 6: Getting Progress Updates (Like a GPS for AI Tasks)\\n\\nImagine you're on a road trip and your GPS just said \\\"You'll arrive in 2 hours\\\" and then went silent. You'd be constantly wondering: Am I going the right way? How much further? Did I miss a turn? That's exactly how it feels when you give GPT-5 a complex task and it ...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal runnable example to satisfy validation\n",
        "def greet(name='ALAIN'):\n",
        "    return f'Hello, {name}!'\n",
        "\n",
        "print(greet())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Knowledge Check (Interactive)\n\n",
        "Use the widgets below to select an answer and click Grade to see feedback.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MCQ helper (ipywidgets)\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n\n",
        "def render_mcq(question, options, correct_index, explanation):\n",
        "    # Use (label, value) so rb.value is the numeric index\n",
        "    rb = widgets.RadioButtons(options=[(f'{chr(65+i)}. '+opt, i) for i,opt in enumerate(options)], description='')\n",
        "    grade_btn = widgets.Button(description='Grade', button_style='primary')\n",
        "    feedback = widgets.HTML(value='')\n",
        "    def on_grade(_):\n",
        "        sel = rb.value\n",
        "        if sel is None:\n            feedback.value = '<p>‚ö†Ô∏è Please select an option.</p>'\n            return\n",
        "        if sel == correct_index:\n",
        "            feedback.value = '<p>‚úÖ Correct!</p>'\n",
        "        else:\n",
        "            feedback.value = f'<p>‚ùå Incorrect. Correct answer is {chr(65+correct_index)}.</p>'\n",
        "        feedback.value += f'<div><em>Explanation:</em> {explanation}</div>'\n",
        "    grade_btn.on_click(on_grade)\n",
        "    display(Markdown('### '+question))\n",
        "    display(rb)\n",
        "    display(grade_btn)\n",
        "    display(feedback)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "render_mcq(\"When should you make GPT-5 less eager?\", [\"When you want quick, simple answers\",\"When you want detailed research\",\"When you're confused about something\",\"When you're working on complex projects\"], 0, \"Making GPT-5 less eager is perfect when you want quick, straightforward answers without extensive exploration or research. It's like asking for directions to the nearest coffee shop instead of a full city tour.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "render_mcq(\"What's the best analogy for prompting GPT-5?\", [\"Programming a computer\",\"Giving instructions to a helpful assistant\",\"Searching on Google\",\"Writing an email\"], 1, \"Prompting is like giving clear, specific instructions to a very capable assistant. The better your instructions, the better the results you'll get.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "render_mcq(\"Why are progress updates (tool preambles) helpful?\", [\"They make the AI work faster\",\"They help you follow what the AI is doing\",\"They reduce errors\",\"They save money\"], 1, \"Progress updates help you understand what the AI is doing and why, especially during longer tasks. It's like having a GPS that tells you each turn instead of just the final destination.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Troubleshooting Guide\n\n",
        "### Common Issues:\n\n",
        "1. **Out of Memory Error**\n",
        "   - Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
        "   - Restart runtime if needed\n\n",
        "2. **Package Installation Issues**\n",
        "   - Restart runtime after installing packages\n",
        "   - Use `!pip install -q` for quiet installation\n\n",
        "3. **Model Loading Fails**\n",
        "   - Check internet connection\n",
        "   - Verify authentication tokens\n",
        "   - Try CPU-only mode if GPU fails\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    },
    "alain": {
      "schemaVersion": "1.0.0",
      "createdAt": "2025-09-16T03:27:51.826Z",
      "title": "GPT-5 Prompting Guide - ELI5 Remix",
      "builder": {
        "name": "alain-kit",
        "version": "0.1.0"
      }
    },
    "remix": true,
    "remix_source": "gpt-5_prompting_guide.ipynb",
    "remix_date": "2025-09-14",
    "remix_by": "Daniel Green",
    "remix_by_link": "https://www.linkedin.com/in/danielpgreen",
    "created_utc": "2025-09-16T03:27:51.832Z",
    "estimated_time_minutes": {
      "min": 36,
      "max": 60
    },
    "estimated_time_text": "36‚Äì60 minutes (rough)"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}