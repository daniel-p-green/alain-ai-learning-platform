{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT\u2011OSS 20B \u2014 Active Learning Notebook (from HF link)\n",
        "\n",
        "Model: https://huggingface.co/openai/gpt-oss-20b\n",
        "\n",
        "[Open in Colab](https://colab.research.google.com/github/YOUR_ORG/YOUR_REPO/blob/main/alain-ai-learning-platform/docs/examples/gpt-oss-20b_active_learning.ipynb)\n",
        "\n",
        "- Outcomes: Engage with GPT\u2011OSS 20B locally via OpenAI\u2011compatible API, with MCQs, a golden\u2011set evaluation, and token/latency logging.\n",
        "- Time: ~45\u201375 minutes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f64831",
      "metadata": {},
      "source": [
        "## About OpenAI and GPT\u2011OSS 20B\n",
        "This lesson uses GPT\u2011OSS 20B as an open\u2011weights model for local experimentation and teaching. It pairs well with an OpenAI\u2011compatible API (e.g., Ollama or vLLM) for fast, local chat.\n",
        "\n",
        "- Company: OpenAI (research and deployment of AI systems)\n",
        "- Model: GPT\u2011OSS 20B (open\u2011weights model used in ALAIN for local, reproducible teaching)\n",
        "- Release date: <add when known>\n",
        "- Why interesting: local, cost\u2011aware experimentation; deterministic evaluations; strong teaching fit.\n",
        "\n",
        "See the model card for details: https://huggingface.co/openai/gpt-oss-20b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d570bb29",
      "metadata": {},
      "source": [
        "### Optional: Fetch Model Card Summary\n",
        "Fetches the model card (if network is available) to display context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7f3c13",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import requests\n",
        "    url = 'https://huggingface.co/openai/gpt-oss-20b/raw/main/README.md'\n",
        "    r = requests.get(url, timeout=8)\n",
        "    if r.status_code == 200:\n",
        "        text = r.text[:2000]\n",
        "        print('--- Model Card (first 2k chars) ---\\n')\n",
        "        print(text)\n",
        "    else:\n",
        "        print('Could not fetch model card:', r.status_code)\n",
        "except Exception as e:\n",
        "    print('Offline or blocked; skip model card. Error:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d5d9112",
      "metadata": {},
      "source": [
        "## Parameters (Colab form)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc13f05",
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Model and Runtime\n",
        "HF_MODEL = 'openai/gpt-oss-20b' #@param {type:'string'}\n",
        "RUNTIME = 'gpt-oss' #@param ['gpt-oss','transformers']\n",
        "GPT_OSS_MODEL = 'gpt-oss:20b' #@param {type:'string'}\n",
        "OPENAI_BASE_URL = 'http://localhost:11434/v1' #@param {type:'string'}\n",
        "TEMPERATURE = 0.0 #@param {type:'number'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074bb7e1",
      "metadata": {},
      "source": [
        "## Install (pinned)\n",
        "If running on Colab, uncomment and run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f9befec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip -q install openai==1.43.0 transformers==4.44.2 datasets==2.20.0 ipywidgets==8.1.3 requests==2.32.3 huggingface_hub==0.24.6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d68f29a9",
      "metadata": {},
      "source": [
        "## Setup & Seeds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b3fa157",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, platform, random, time\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "\n",
        "import numpy as np\n",
        "SEED=42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "try:\n",
        "    import torch\n",
        "    torch.manual_seed(SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        print('CUDA device:', torch.cuda.get_device_name(0))\n",
        "    else:\n",
        "        print('CUDA not available')\n",
        "except Exception as e:\n",
        "    print('Torch not installed; skipping torch seed.', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94df939d",
      "metadata": {},
      "source": [
        "## Secrets\n",
        "Keys are read from environment if needed; no hardcoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de7f445c",
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', 'ollama')\n",
        "print('Have OPENAI_API_KEY:', bool(OPENAI_API_KEY))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec021ab",
      "metadata": {},
      "source": [
        "## Quickstart (GPT\u2011OSS local via OpenAI\u2011compatible API)\n",
        "Ensure you have an OpenAI\u2011compatible server (e.g., Ollama) with `gpt-oss:20b` available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e63eeac",
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(base_url=OPENAI_BASE_URL, api_key=OPENAI_API_KEY)\n",
        "\n",
        "def chat(prompt: str, model: str = None, temperature: float = None):\n",
        "    model = model or GPT_OSS_MODEL\n",
        "    temperature = temperature if temperature is not None else TEMPERATURE\n",
        "    t0 = time.time()\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{'role':'user','content':prompt}],\n",
        "        temperature=temperature\n",
        "    )\n",
        "    dt = time.time()-t0\n",
        "    txt = resp.choices[0].message.content\n",
        "    usage = getattr(resp,'usage',None)\n",
        "    print(txt)\n",
        "    if usage:\n",
        "        print('Tokens total:', getattr(usage,'total_tokens',None))\n",
        "    print(f'Latency: {dt:.2f}s')\n",
        "    return txt\n",
        "\n",
        "_ = chat('Say hello in five words.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b0c349a",
      "metadata": {},
      "source": [
        "## Background: Model Card At-a-Glance\n",
        "Pulls key metadata from Hugging Face for quick context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3ea0cdd",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from huggingface_hub import HfApi\n",
        "    api = HfApi()\n",
        "    info = api.model_info(HF_MODEL)\n",
        "    print('Model:', info.modelId)\n",
        "    print('Likes:', getattr(info, 'likes', None), '  Downloads:', getattr(info, 'downloads', None))\n",
        "    print('Last modified:', getattr(info, 'lastModified', None))\n",
        "    print('Library:', getattr(info, 'library_name', None), '  Pipeline:', getattr(info, 'pipeline_tag', None))\n",
        "    print('License:', getattr(info, 'license', None))\n",
        "    tags = list(getattr(info, 'tags', []) or [])\n",
        "    print('Tags:', ', '.join(tags[:12]) + (' \u2026' if len(tags)>12 else ''))\n",
        "except Exception as e:\n",
        "    print('Could not load model info (offline or missing huggingface_hub):', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55816943",
      "metadata": {},
      "source": [
        "## ELI5 Summaries\n",
        "Explain the model in simple terms for different audiences. Uses GPT\u2011OSS if available; otherwise prints a short extract.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bea0e358",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_model_card(max_chars=6000):\n",
        "    try:\n",
        "        import requests\n",
        "        url = f'https://huggingface.co/{HF_MODEL}/raw/main/README.md'\n",
        "        r = requests.get(url, timeout=10)\n",
        "        if r.status_code == 200:\n",
        "            return r.text[:max_chars]\n",
        "    except Exception as e:\n",
        "        print('Fetch error:', e)\n",
        "    return None\n",
        "\n",
        "card = fetch_model_card()\n",
        "if card and 'chat' in globals() and RUNTIME=='gpt-oss':\n",
        "    prompt = f'''Summarize the following model card for three audiences.\n",
        "\n",
        "1) Developer ELI5: What is this model, how to use it, main params, and caveats.\n",
        "2) Product Manager ELI5: What it enables, top constraints, and cost/latency notes.\n",
        "3) CTO ELI5: Deployment shape (local vs cloud), license/signals, observability.\n",
        "\n",
        "Return concise bullet lists for each audience.\n",
        "---\n",
        "{card}\n",
        "---'''.strip()\n",
        "    _ = chat(prompt)\n",
        "elif card:\n",
        "    print('ELI5 (extract):')\n",
        "    print('\n",
        "'.join(card.splitlines()[:20]))\n",
        "else:\n",
        "    print('Model card unavailable; run later or ensure network access.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d7819c1",
      "metadata": {},
      "source": [
        "## Release Notes & License\n",
        "Key details to know before you ship or evaluate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e373a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from huggingface_hub import HfApi\n",
        "    import re\n",
        "    api=HfApi()\n",
        "    info=api.model_info(HF_MODEL)\n",
        "    print('Last modified:', getattr(info,'lastModified', None))\n",
        "    print('License:', getattr(info,'license', None))\n",
        "    import requests\n",
        "    url=f'https://huggingface.co/{HF_MODEL}/raw/main/README.md'\n",
        "    r=requests.get(url,timeout=10)\n",
        "    if r.status_code==200:\n",
        "        md=r.text\n",
        "        def extract(section):\n",
        "            m=re.search(r'(^|\\n)#+\\s*'+re.escape(section)+r'[^\\n]*\\n(.+?)(\\n#+|\\Z)', md, re.S|re.I)\n",
        "            return (m.group(2).strip() if m else None)\n",
        "        for sec in ['Intended Use','Use cases','Limitations','Risks','Training data','Model details','License']:\n",
        "            txt=extract(sec)\n",
        "            if txt:\n",
        "                print(f'--- {sec} ---')\n",
        "                print('\n",
        "'.join(txt.splitlines()[:20]))\n",
        "except Exception as e:\n",
        "    print('Could not load release notes/license details:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intended Use & Limitations (from Model Card)\n",
        "Quickly scan the most relevant sections from the README.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re, requests\n",
        "\n",
        "def fetch_readme(org_model: str, timeout: int = 10):\n",
        "    url = f'https://huggingface.co/{org_model}/raw/main/README.md'\n",
        "    try:\n",
        "        r = requests.get(url, timeout=timeout)\n",
        "        if r.status_code == 200:\n",
        "            return r.text\n",
        "    except Exception as e:\n",
        "        print('Fetch error:', e)\n",
        "    return None\n",
        "\n",
        "def extract_sections(md_text: str, sections):\n",
        "    out = {}\n",
        "    for sec in sections:\n",
        "        m = re.search(r'(^|\\n)#+\\s*' + re.escape(sec) + r'[^\\n]*\\n(.+?)(\\n#+|\\Z)', md_text, re.S | re.I)\n",
        "        if m:\n",
        "            out[sec] = m.group(2).strip()\n",
        "    return out\n",
        "\n",
        "md = fetch_readme(HF_MODEL)\n",
        "secs = extract_sections(md or '', ['Intended Use','Use cases','Limitations','Risks','Training data'])\n",
        "for k,v in secs.items():\n",
        "    print(f'\n--- {k} ---\n')\n",
        "    print('\n'.join(v.splitlines()[:30]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4821ae8",
      "metadata": {},
      "source": [
        "## Adjacent Models to Explore\n",
        "Suggestions based on tags/org; helpful for comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dcf5b27",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from huggingface_hub import HfApi\n",
        "    api=HfApi()\n",
        "    models=list(api.list_models(author='openai', sort='downloads', direction=-1))[:20]\n",
        "    rec=[m.modelId for m in models if ('gpt' in m.modelId.lower() or 'oss' in m.modelId.lower()) and m.modelId!='openai/gpt-oss-20b']\n",
        "    for m in rec[:10]:\n",
        "        print('-', m)\n",
        "except Exception as e:\n",
        "    print('Could not fetch adjacent models:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "819e6d3d",
      "metadata": {},
      "source": [
        "## Metaphors & Simple Explanations\n",
        "Explain the model in everyday language and give concrete examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8ed3fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'chat' in globals() and RUNTIME=='gpt-oss':\n",
        "    prompt=(\n",
        "        'Explain GPT-OSS 20B to a busy developer using a real-world metaphor (e.g., toolbelt, kitchen).\\n'\n",
        "        'Then give 3 concrete examples of tasks it does well and 2 it does poorly, with one-liners why.'\n",
        "    )\n",
        "    _=chat(prompt)\n",
        "else:\n",
        "    print('Metaphor: Think of the model as a \"multitool writer\"\u2014it can draft, summarize, and reformat text.\\n'\n",
        "          'Good at: short drafting, structured transformations, explaining code.\\n'\n",
        "          'Poor at: long-term memory, exact factual recall without grounding.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5faed292",
      "metadata": {},
      "source": [
        "## Guided Steps\n",
        "1. Explore core parameters (temperature, max tokens).\n",
        "2. Add a structured output (JSON) or schema validation.\n",
        "3. Run a small batch; measure latency and (if exposed) tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a27bde",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pydantic schema hint (optional)\n",
        "try:\n",
        "    from pydantic import BaseModel\n",
        "    class Item(BaseModel):\n",
        "        title: str\n",
        "        rating: int\n",
        "    print('Use Item.model_json_schema() to prompt for strict JSON and validate outputs.')\n",
        "except Exception:\n",
        "    print('Install pydantic to validate structured outputs.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13148e12",
      "metadata": {},
      "source": [
        "## Evaluation (Golden Set)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad5eb02",
      "metadata": {},
      "outputs": [],
      "source": [
        "golden = [\n",
        "    {'prompt':'2+2?','expect':'4'},\n",
        "    {'prompt':'Capital of France?','expect':'Paris'},\n",
        "]\n",
        "ok=0\n",
        "for ex in golden:\n",
        "    out = chat(ex['prompt'])\n",
        "    ok += int(ex['expect'].lower() in (out or '').lower())\n",
        "acc = ok/len(golden)\n",
        "print(f'Accuracy: {acc:.2%} ({ok}/{len(golden)})')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ecffb6b",
      "metadata": {},
      "source": [
        "## MCQ \u2014 Understanding Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "710b56eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = 'Which parameter most reduces randomness?'\n",
        "options = ['top_p','temperature','max_tokens','presence_penalty']\n",
        "correct_index = 1\n",
        "explanation = 'Lower temperature yields more deterministic outputs.'\n",
        "print(question)\n",
        "for i,o in enumerate(options):\n",
        "    print(f'  {i}) {o}')\n",
        "try:\n",
        "    import ipywidgets as W\n",
        "    from IPython.display import display\n",
        "    dd = W.Dropdown(options=[(o,i) for i,o in enumerate(options)], description='Answer:')\n",
        "    btn = W.Button(description='Submit')\n",
        "    out = W.Output()\n",
        "    def on_click(_):\n",
        "        with out:\n",
        "            out.clear_output()\n",
        "            print('Correct!' if dd.value==correct_index else f'Not quite. {explanation}')\n",
        "    btn.on_click(on_click)\n",
        "    display(dd, btn, out)\n",
        "except Exception:\n",
        "    choice = int(input('Your choice (0-3): ').strip() or -1)\n",
        "    print('Correct!' if choice==correct_index else f'Not quite. {explanation}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a589611",
      "metadata": {},
      "source": [
        "## MCQ \u2014 Tokens & Costs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b85180d",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = 'Which fields commonly indicate token usage in OpenAI-compatible responses?'\n",
        "options = ['usage.prompt_tokens & usage.completion_tokens', 'num_tokens & token_count', 'price.prompt & price.completion', 'gpu_tokens & cpu_tokens']\n",
        "correct_index = 0\n",
        "explanation = 'Look for usage.prompt_tokens, usage.completion_tokens, and sometimes total_tokens.'\n",
        "print(question)\n",
        "for i,o in enumerate(options):\n",
        "    print(f'  {i}) {o}')\n",
        "choice = int(input('Your choice (0-3): ').strip() or -1)\n",
        "print('Correct!' if choice==correct_index else f'Not quite. {explanation}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf5a6f93",
      "metadata": {},
      "source": [
        "## MCQ \u2014 Secrets & Safety\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dda40cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = 'What is the safest way to use API keys in notebooks?'\n",
        "options = ['Hardcode in code cells', 'Store in environment variables and read with os.getenv', 'Embed in the prompt', 'Commit to git and rotate later']\n",
        "correct_index = 1\n",
        "explanation = 'Read secrets from environment variables; never hardcode or commit.'\n",
        "print(question)\n",
        "for i,o in enumerate(options):\n",
        "    print(f'  {i}) {o}')\n",
        "choice = int(input('Your choice (0-3): ').strip() or -1)\n",
        "print('Correct!' if choice==correct_index else f'Not quite. {explanation}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84540235",
      "metadata": {},
      "source": [
        "## Customization Playground\n",
        "Experiment with prompt and parameters interactively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa65bc8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import ipywidgets as W\n",
        "    from IPython.display import display\n",
        "    prompt_w = W.Text(value='Summarize this lesson in 20 words.', description='Prompt:', layout=W.Layout(width='90%'))\n",
        "    temp_w = W.FloatSlider(value=float(TEMPERATURE), min=0.0, max=1.0, step=0.1, description='Temp')\n",
        "    btn = W.Button(description='Run')\n",
        "    out = W.Output()\n",
        "    def on_click(_):\n",
        "        with out:\n",
        "            out.clear_output()\n",
        "            txt = chat(prompt_w.value) if RUNTIME=='gpt-oss' else 'Switch RUNTIME to transformers if needed.'\n",
        "            print('--- Output ---')\n",
        "            print(txt)\n",
        "    btn.on_click(on_click)\n",
        "    display(prompt_w, temp_w, btn, out)\n",
        "except Exception as e:\n",
        "    print('Widgets unavailable; use chat(\\'...\\') directly.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfda3586",
      "metadata": {},
      "source": [
        "## Cost & Observability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d41c1c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts = ['List 3 cities in 5 words','Name 3 fruits in 5 words']\n",
        "t0=time.time(); outs=[]\n",
        "for p in prompts:\n",
        "    outs.append(chat(p))\n",
        "dt=time.time()-t0\n",
        "print('Batch latency:', round(dt,2),'s for', len(prompts),'items')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c5d6e1a",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "- Add a JSON schema and validate outputs.\n",
        "- Expand the golden set to 20 items and report accuracy.\n",
        "- Log average latency over 10 trials at two temperatures.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b434776",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What changed when you varied temperature from 0.0 to 0.8?\n",
        "- How would you adapt the prompt for structured JSON output?\n",
        "- Which exercises would reveal model limitations most clearly?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "- Connection errors: verify `OPENAI_BASE_URL` and that your server exposes `/models`.\n",
        "- 401/403: check keys/permissions; never hardcode secrets.\n",
        "- OOM: reduce sequence length/batch; switch to CPU or smaller model.\n",
        "- JSON parse errors: strip code fences; validate/repair before loads.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diagnostics\n",
        "import requests\n",
        "try:\n",
        "    r = requests.get(OPENAI_BASE_URL + '/models', timeout=5)\n",
        "    print(r.status_code, r.text[:200])\n",
        "except Exception as e:\n",
        "    print('Conn error:', e)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}