# context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16

This is an offline research capsule for context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16.

## At a Glance
- Architecture: LlamaForCausalLM
- Parameters: 1.23â€¯B
- Context window: 131072
- Tokenizer: vocab_size=128000?
- License: llama3.2
- Primary sources captured: 20
- Primary repository: meta-llama/llama-models

## Coverage

- Coverage score: 8/10 (~80% )
- Missing metadata: inference hardware, license SPDX

## Files
- Sources digest: sources_digest.md
- Raw sources under sources/
- See TECH_SPECS.md and LICENSE_NOTES.md for extracted details.