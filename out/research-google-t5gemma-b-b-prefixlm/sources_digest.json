{
  "model_id": "google/t5gemma-b-b-prefixlm",
  "revision": "df5e1422c2a53948a57901c54bfcf397c92bfa1d",
  "files": {
    "hf_readme": true,
    "config": false,
    "generation_config": false,
    "tokenizer_json": false,
    "tokenizer_model": false,
    "gh_readme": false,
    "gh_license": false,
    "gh_citation": false,
    "gh_release": false,
    "arxiv_meta": true,
    "dataset_cards": false
  },
  "datasets": [],
  "manifest_entries": 3,
  "metadata": {
    "license": "gemma",
    "license_source": "README front-matter",
    "usage_sections": [
      "### Usage\n\nBelow we share some code snippets on how to get quickly started with running the model. First, install the Transformers library with:\n```sh\npip install -U transformers\n```\n\nThen, copy the snippet from the section that is relevant for your usecase.\n",
      "## Usage and Limitations\n\nThese models have certain limitations that users should be aware of.\n",
      "### Intended Usage\n\nOpen large language models (LLMs) models have a wide range of applications across various industries and domains. The following list of potential uses is not comprehensive. The purpose of this list is to provide contextual information about the possible use-cases that the model creators considered as part of model training and development.\n\n- Content Creation and Communication\n  - Text Generation: These models can be used to generate creative text formats such as poems, scripts, code, marketing copy, and email drafts.\n  - Text Summarization: Generate concise summaries of a text corpus, research papers, or reports.\n\n- Research and Education\n  - Natural Language Processing (NLP) Research: These models can serve as a foundation for researchers to experiment with NLP techniques, develop algorithms, and contribute to the advancement of the field.\n"
    ],
    "evals": [
      {
        "benchmark": "[MMLU](https://arxiv.org/abs/2009.03300)",
        "metric": "5-shot, top-1",
        "source": "README"
      },
      {
        "benchmark": "[HellaSwag](https://arxiv.org/abs/1905.07830)",
        "metric": "10-shot",
        "source": "README"
      },
      {
        "benchmark": "[PIQA](https://arxiv.org/abs/1911.11641)",
        "metric": "0-shot",
        "source": "README"
      },
      {
        "benchmark": "[BoolQ](https://arxiv.org/abs/1905.10044)",
        "metric": "0-shot",
        "source": "README"
      },
      {
        "benchmark": "[WinoGrande](https://arxiv.org/abs/1907.10641)",
        "metric": "partial score",
        "source": "README"
      },
      {
        "benchmark": "[ARC-e](https://arxiv.org/abs/1911.01547)",
        "metric": "0-shot",
        "source": "README"
      },
      {
        "benchmark": "[ARC-c](https://arxiv.org/abs/1911.01547)",
        "metric": "25-shot",
        "source": "README"
      },
      {
        "benchmark": "[TriviaQA](https://arxiv.org/abs/1705.03551)",
        "metric": "5-shot",
        "source": "README"
      },
      {
        "benchmark": "[Natural Questions](https://github.com/google-research-datasets/natural-questions)",
        "metric": "5-shot",
        "source": "README"
      },
      {
        "benchmark": "[HumanEval](https://arxiv.org/abs/2107.03374)",
        "metric": "pass@1",
        "source": "README"
      },
      {
        "benchmark": "[MBPP](https://arxiv.org/abs/2108.07732)",
        "metric": "3-shot",
        "source": "README"
      },
      {
        "benchmark": "[GSM8K](https://arxiv.org/abs/2110.14168)",
        "metric": "5-shot, maj@1",
        "source": "README"
      },
      {
        "benchmark": "[MATH-500](https://arxiv.org/abs/2103.03874)",
        "metric": "4-shot",
        "source": "README"
      },
      {
        "benchmark": "[AGIEval](https://arxiv.org/abs/2304.06364)",
        "metric": "3-5-shot",
        "source": "README"
      },
      {
        "benchmark": "[BIG-Bench](https://arxiv.org/abs/2206.04615)",
        "metric": "3-shot, CoT",
        "source": "README"
      }
    ],
    "coverage": {
      "filled": 2,
      "total": 10,
      "missing": [
        "architecture",
        "parameters",
        "context window",
        "tokenizer",
        "primary repo",
        "inference hardware",
        "tokenizer vocab",
        "license SPDX"
      ],
      "score": 20
    },
    "versioning": {
      "hf_revision": "df5e1422c2a53948a57901c54bfcf397c92bfa1d"
    },
    "flags": [
      "incomplete_metadata",
      "missing_primary_repo"
    ]
  }
}