{
  "model_id": "openai/gpt-oss-20b",
  "revision": "6cee5e81ee83917806bbde320786a8fb61efebee",
  "files": {
    "hf_readme": true,
    "config": true,
    "generation_config": true,
    "tokenizer_json": true,
    "tokenizer_model": false,
    "gh_readme": true,
    "gh_license": true,
    "gh_citation": false,
    "gh_release": true,
    "arxiv_meta": true,
    "dataset_cards": false
  },
  "datasets": [],
  "manifest_entries": 14,
  "metadata": {
    "license": "Apache-2.0",
    "license_source": "README front-matter",
    "architecture": "GptOssForCausalLM",
    "context_window": "131072",
    "tokenizer_details": {
      "vocab_size": "201088"
    },
    "versioning": {
      "hf_revision": "6cee5e81ee83917806bbde320786a8fb61efebee"
    },
    "inference": {
      "quantization": [
        "modules_to_not_convert:model.layers.*.self_attn,model.layers.*.mlp.router,model.embed_tokens,lm_head",
        "quant_method:mxfp4"
      ]
    },
    "parameters": "117B",
    "usage_sections": [
      "# Inference examples\n"
    ],
    "evals": [
      {
        "benchmark": "`gpt-oss",
        "metric": "b` — for production, general purpose, high reasoning use cases that fit into a single 80GB GPU (like NVIDIA H100 or AMD MI300X) (117B parameters with 5.1B active parameters)",
        "score": "120",
        "source": "README"
      },
      {
        "benchmark": "`gpt-oss",
        "metric": "b` — for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters)",
        "score": "20",
        "source": "README"
      },
      {
        "benchmark": "-attn_implementation sdpa_paged<!-- HTML_TAG_END --></pre></div>  <h3 class=\"relative group\"><a id=\"performance-tips\" class=\"header-link block pr",
        "metric": "text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#performance-tips\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Performance tips</span></h3> <ul data-svelte-h=\"svelte-1pthljr\"><li>Use an efficient attention backend when available:</li></ul> <div class=\"code-block relative \"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->transformers serve \\",
        "score": "1.5",
        "source": "link:https://huggingface.co/docs/transformers/main/serving"
      },
      {
        "benchmark": "[Use gpt-oss",
        "metric": "b with LM Studio](https://lmstudio.ai/models/openai/gpt-oss-20b)",
        "score": "20",
        "source": "link:https://raw.githubusercontent.com/openai/gpt-oss/main/awesome-gpt-oss.md"
      },
      {
        "benchmark": "[Use gpt-oss",
        "metric": "b with LM Studio](https://lmstudio.ai/models/openai/gpt-oss-120b)",
        "score": "120",
        "source": "link:https://raw.githubusercontent.com/openai/gpt-oss/main/awesome-gpt-oss.md"
      },
      {
        "benchmark": "[gpt-oss",
        "metric": "b model on the GroqCloud Playground](https://console.groq.com/playground?model=openai/gpt-oss-120b)",
        "score": "120",
        "source": "link:https://raw.githubusercontent.com/openai/gpt-oss/main/awesome-gpt-oss.md"
      },
      {
        "benchmark": "[gpt-oss",
        "metric": "b model on the GroqCloud Playground](https://console.groq.com/playground?model=openai/gpt-oss-20b)",
        "score": "20",
        "source": "link:https://raw.githubusercontent.com/openai/gpt-oss/main/awesome-gpt-oss.md"
      },
      {
        "benchmark": "Use [gpt-oss",
        "metric": "b](https://build.nvidia.com/openai/gpt-oss-120b) and [gpt-oss-20b](https://build.nvidia.com/openai/gpt-oss-20b) on NVIDIA's Cloud",
        "score": "120",
        "source": "link:https://raw.githubusercontent.com/openai/gpt-oss/main/awesome-gpt-oss.md"
      },
      {
        "benchmark": "[gpt-oss",
        "metric": "b on Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/models/gpt-oss-120b)",
        "score": "120",
        "source": "link:https://raw.githubusercontent.com/openai/gpt-oss/main/awesome-gpt-oss.md"
      },
      {
        "benchmark": "[gpt-oss",
        "metric": "b on Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/models/gpt-oss-20b)",
        "score": "20",
        "source": "link:https://raw.githubusercontent.com/openai/gpt-oss/main/awesome-gpt-oss.md"
      },
      {
        "benchmark": "[gpt-oss",
        "metric": "B on AMD MI300X](https://huggingface.co/spaces/amd/gpt-oss-120b-chatbot)",
        "score": "120",
        "source": "link:https://raw.githubusercontent.com/openai/gpt-oss/main/awesome-gpt-oss.md"
      }
    ],
    "license_details": {
      "spdx": "Apache-2.0"
    },
    "coverage": {
      "filled": 7,
      "total": 10,
      "missing": [
        "tokenizer",
        "primary repo",
        "inference hardware"
      ],
      "score": 70
    },
    "primary_repo": "openai/gpt-oss",
    "notes": "Generated offline from harvested metadata (LM spec unavailable)."
  }
}