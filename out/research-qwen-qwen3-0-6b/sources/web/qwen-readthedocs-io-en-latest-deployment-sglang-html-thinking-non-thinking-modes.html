<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="vLLM" href="vllm.html" /><link rel="prev" title="MLX LM" href="../run_locally/mlx-lm.html" />

    <!-- Generated with Sphinx 7.4.7 and Furo 2025.07.19 -->
        <title>SGLang - Qwen</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=ab9a3e09" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style><script async type="text/javascript" src="/_/static/javascript/readthedocs-addons.js"></script><meta name="readthedocs-project-slug" content="qwen" /><meta name="readthedocs-version-slug" content="latest" /><meta name="readthedocs-resolver-filename" content="/deployment/sglang.html" /><meta name="readthedocs-http-status" content="200" /></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Qwen</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-scroll"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">Qwen</span>
  
</a><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/concepts.html">Key Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/speed_benchmark.html">Speed Benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/quantization_benchmark.html">Performance of Quantized Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../inference/transformers.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Run Locally</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../run_locally/llama.cpp.html">llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../run_locally/ollama.html">Ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="../run_locally/mlx-lm.html">MLX LM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="vllm.html">vLLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="tgi.html">TGI</a></li>
<li class="toctree-l1"><a class="reference internal" href="dstack.html">dstack</a></li>
<li class="toctree-l1"><a class="reference internal" href="skypilot.html">SkyPilot</a></li>
<li class="toctree-l1"><a class="reference internal" href="openllm.html">OpenLLM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quantization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quantization/awq.html">AWQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization/gptq.html">GPTQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization/llama.cpp.html">llama.cpp</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../training/axolotl.html">Axolotl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/llama_factory.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/ms_swift.html">MS-SWIFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/unsloth.html">Unsloth</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/verl.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Framework</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../framework/qwen_agent.html">Qwen-Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/function_call.html">Function Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/LlamaIndex.html">LlamaIndex</a></li>
<li class="toctree-l1"><a class="reference internal" href="../framework/Langchain.html">Langchain</a></li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/deployment/sglang.md.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="sglang">
<h1>SGLang<a class="headerlink" href="#sglang" title="Link to this heading">¶</a></h1>
<p><a class="reference external" href="https://github.com/sgl-project/sglang">SGLang</a> is a fast serving framework for large language models and vision language models.</p>
<p>To learn more about SGLang, please refer to the <a class="reference external" href="https://docs.sglang.ai/">documentation</a>.</p>
<section id="environment-setup">
<h2>Environment Setup<a class="headerlink" href="#environment-setup" title="Link to this heading">¶</a></h2>
<p>By default, you can install <code class="docutils literal notranslate"><span class="pre">sglang</span></code> with pip in a clean environment:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;sglang[all]&gt;=0.4.6.post1&quot;</span>
</pre></div>
</div>
<p>If you have encountered issues in installation, please feel free to check the official document for installation (<a class="reference external" href="https://docs.sglang.ai/start/install.html">link</a>).</p>
</section>
<section id="api-service">
<h2>API Service<a class="headerlink" href="#api-service" title="Link to this heading">¶</a></h2>
<p>It is easy to build an OpenAI-compatible API service with SGLang, which can be deployed as a server that implements OpenAI API protocol.
By default, it starts the server at <code class="docutils literal notranslate"><span class="pre">http://localhost:30000</span></code>.
You can specify the address with <code class="docutils literal notranslate"><span class="pre">--host</span></code> and <code class="docutils literal notranslate"><span class="pre">--port</span></code> arguments.
Run the command as shown below:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>Qwen/Qwen3-8B
</pre></div>
</div>
<p>By default, if the <code class="docutils literal notranslate"><span class="pre">--model-path</span></code> does not point to a valid local directory, it will download the model files from the Hugging Face Hub.
To download model from ModelScope, set the following before running the above command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">SGLANG_USE_MODELSCOPE</span><span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<p>For distributed inference with tensor parallelism, it is as simple as</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span>--tensor-parallel-size<span class="w"> </span><span class="m">4</span>
</pre></div>
</div>
<p>The above command will use tensor parallelism on 4 GPUs.
You should change the number of GPUs according to your demand.</p>
<section id="basic-usage">
<h3>Basic Usage<a class="headerlink" href="#basic-usage" title="Link to this heading">¶</a></h3>
<p>Then, you can use the <a class="reference external" href="https://platform.openai.com/docs/api-reference/chat/completions/create">create chat interface</a> to communicate with Qwen:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
curl</label><div class="sd-tab-content docutils">
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:30000/v1/chat/completions<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">  &quot;model&quot;: &quot;Qwen/Qwen3-8B&quot;,</span>
<span class="s1">  &quot;messages&quot;: [</span>
<span class="s1">    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Give me a short introduction to large language models.&quot;}</span>
<span class="s1">  ],</span>
<span class="s1">  &quot;temperature&quot;: 0.6,</span>
<span class="s1">  &quot;top_p&quot;: 0.95,</span>
<span class="s1">  &quot;top_k&quot;: 20,</span>
<span class="s1">  &quot;max_tokens&quot;: 32768</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
Python</label><div class="sd-tab-content docutils">
<p>You can use the API client with the <code class="docutils literal notranslate"><span class="pre">openai</span></code> Python SDK as shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="c1"># Set OpenAI&#39;s API key and API base to use SGLang&#39;s API server.</span>
<span class="n">openai_api_key</span> <span class="o">=</span> <span class="s2">&quot;EMPTY&quot;</span>
<span class="n">openai_api_base</span> <span class="o">=</span> <span class="s2">&quot;http://localhost:30000/v1&quot;</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">,</span>
    <span class="n">base_url</span><span class="o">=</span><span class="n">openai_api_base</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">chat_response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Qwen/Qwen3-8B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me a short introduction to large language models.&quot;</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">32768</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="p">},</span> 
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Chat response:&quot;</span><span class="p">,</span> <span class="n">chat_response</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>While the default sampling parameters would work most of the time for thinking mode,
it is recommended to adjust the sampling parameters according to your application,
and always pass the sampling parameters to the API.</p>
</div>
</section>
<section id="thinking-non-thinking-modes">
<h3>Thinking &amp; Non-Thinking Modes<a class="headerlink" href="#thinking-non-thinking-modes" title="Link to this heading">¶</a></h3>
<p>Qwen3 models will think before respond.
This behavior could be controlled by either the hard switch, which could disable thinking completely, or the soft switch, where the model follows the instruction of the user on whether it should think.</p>
<p>The hard switch is available in SGLang through the following configuration to the API call.
To disable thinking, use</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-2" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
curl</label><div class="sd-tab-content docutils">
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:30000/v1/chat/completions<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">  &quot;model&quot;: &quot;Qwen/Qwen3-8B&quot;,</span>
<span class="s1">  &quot;messages&quot;: [</span>
<span class="s1">    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Give me a short introduction to large language models.&quot;}</span>
<span class="s1">  ],</span>
<span class="s1">  &quot;temperature&quot;: 0.7,</span>
<span class="s1">  &quot;top_p&quot;: 0.8,</span>
<span class="s1">  &quot;top_k&quot;: 20,</span>
<span class="s1">  &quot;max_tokens&quot;: 8192,</span>
<span class="s1">  &quot;presence_penalty&quot;: 1.5,</span>
<span class="s1">  &quot;chat_template_kwargs&quot;: {&quot;enable_thinking&quot;: false}</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Python</label><div class="sd-tab-content docutils">
<p>You can use the API client with the <code class="docutils literal notranslate"><span class="pre">openai</span></code> Python SDK as shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="c1"># Set OpenAI&#39;s API key and API base to use SGLang&#39;s API server.</span>
<span class="n">openai_api_key</span> <span class="o">=</span> <span class="s2">&quot;EMPTY&quot;</span>
<span class="n">openai_api_base</span> <span class="o">=</span> <span class="s2">&quot;http://localhost:30000/v1&quot;</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">,</span>
    <span class="n">base_url</span><span class="o">=</span><span class="n">openai_api_base</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">chat_response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Qwen/Qwen3-8B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me a short introduction to large language models.&quot;</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">8192</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">presence_penalty</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
        <span class="s2">&quot;chat_template_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;enable_thinking&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Chat response:&quot;</span><span class="p">,</span> <span class="n">chat_response</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please note that passing <code class="docutils literal notranslate"><span class="pre">enable_thinking</span></code> is not OpenAI API compatible.
The exact method may differ among frameworks.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>To completely disable thinking, you could use <a class="reference download internal" download="" href="../_downloads/c101120b5bebcc2f12ec504fc93a965e/qwen3_nonthinking.jinja"><span class="xref download myst">a custom chat template</span></a> when starting the model:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span>--chat-template<span class="w"> </span>./qwen3_nonthinking.jinja
</pre></div>
</div>
<p>The chat template prevents the model from generating thinking content, even if the user instructs the model to do so with <code class="docutils literal notranslate"><span class="pre">/think</span></code>.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>It is recommended to set sampling parameters differently for thinking and non-thinking modes.</p>
</div>
</section>
<section id="parsing-thinking-content">
<h3>Parsing Thinking Content<a class="headerlink" href="#parsing-thinking-content" title="Link to this heading">¶</a></h3>
<p>SGLang supports parsing the thinking content from the model generation into structured messages:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span>--reasoning-parser<span class="w"> </span>qwen3
</pre></div>
</div>
<p>The response message will have a field named <code class="docutils literal notranslate"><span class="pre">reasoning_content</span></code> in addition to <code class="docutils literal notranslate"><span class="pre">content</span></code>, containing the thinking content generated by the model.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please note that this feature is not OpenAI API compatible.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><code class="docutils literal notranslate"><span class="pre">enable_thinking=False</span></code> may not be compatible with this feature.
If you need to pass <code class="docutils literal notranslate"><span class="pre">enable_thinking=False</span></code> to the API, please consider disabling parsing thinking content.</p>
</div>
</section>
<section id="parsing-tool-calls">
<h3>Parsing Tool Calls<a class="headerlink" href="#parsing-tool-calls" title="Link to this heading">¶</a></h3>
<p>SGLang supports parsing the tool calling content from the model generation into structured messages:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span>--tool-call-parser<span class="w"> </span>qwen25
</pre></div>
</div>
<p>For more information, please refer to <a class="reference internal" href="../framework/function_call.html"><span class="std std-doc">our guide on Function Calling</span></a>.</p>
</section>
<section id="structured-json-output">
<h3>Structured/JSON Output<a class="headerlink" href="#structured-json-output" title="Link to this heading">¶</a></h3>
<p>SGLang supports structured/JSON output.
Please refer to <a class="reference external" href="https://docs.sglang.ai/backend/structured_outputs.html#OpenAI-Compatible-API">SGLang’s documentation</a>.
Besides, it is also recommended to instruct the model to generate the specific format in the system message or in your prompt.</p>
</section>
<section id="serving-quantized-models">
<h3>Serving Quantized models<a class="headerlink" href="#serving-quantized-models" title="Link to this heading">¶</a></h3>
<p>Qwen3 comes with two types of pre-quantized models, FP8 and AWQ.</p>
<p>The command serving those models are the same as the original models except for the name change:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># For FP8 quantized model</span>
python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>Qwen/Qwen3-8B-FP8

<span class="c1"># For AWQ quantized model</span>
python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>Qwen/Qwen3-8B-AWQ
</pre></div>
</div>
</section>
<section id="context-length">
<h3>Context Length<a class="headerlink" href="#context-length" title="Link to this heading">¶</a></h3>
<p>The context length for Qwen3 models in pretraining is up to 32,768 tokens.
To handle context length substantially exceeding 32,768 tokens, RoPE scaling techniques should be applied.
We have validated the performance of <a class="reference external" href="https://arxiv.org/abs/2309.00071">YaRN</a>, a technique for enhancing model length extrapolation, ensuring optimal performance on lengthy texts.</p>
<p>SGLang supports YaRN, which can be configured as</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span>--json-model-override-args<span class="w"> </span><span class="s1">&#39;{&quot;rope_scaling&quot;:{&quot;rope_type&quot;:&quot;yarn&quot;,&quot;factor&quot;:4.0,&quot;original_max_position_embeddings&quot;:32768}}&#39;</span><span class="w"> </span>--context-length<span class="w"> </span><span class="m">131072</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>SGLang implements static YaRN, which means the scaling factor remains constant regardless of input length, <strong>potentially impacting performance on shorter texts.</strong>
We advise adding the <code class="docutils literal notranslate"><span class="pre">rope_scaling</span></code> configuration only when processing long contexts is required.
It is also recommended to modify the <code class="docutils literal notranslate"><span class="pre">factor</span></code> as needed. For example, if the typical context length for your application is 65,536 tokens, it would be better to set <code class="docutils literal notranslate"><span class="pre">factor</span></code> as 2.0.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default <code class="docutils literal notranslate"><span class="pre">max_position_embeddings</span></code> in <code class="docutils literal notranslate"><span class="pre">config.json</span></code> is set to 40,960, which is used by SGLang.
This allocation includes reserving 32,768 tokens for outputs and 8,192 tokens for typical prompts, which is sufficient for most scenarios involving short text processing and leave adequate room for model thinking.
If the average context length does not exceed 32,768 tokens, we do not recommend enabling YaRN in this scenario, as it may potentially degrade model performance.</p>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="vllm.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">vLLM</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../run_locally/mlx-lm.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">MLX LM</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Qwen Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">SGLang</a><ul>
<li><a class="reference internal" href="#environment-setup">Environment Setup</a></li>
<li><a class="reference internal" href="#api-service">API Service</a><ul>
<li><a class="reference internal" href="#basic-usage">Basic Usage</a></li>
<li><a class="reference internal" href="#thinking-non-thinking-modes">Thinking &amp; Non-Thinking Modes</a></li>
<li><a class="reference internal" href="#parsing-thinking-content">Parsing Thinking Content</a></li>
<li><a class="reference internal" href="#parsing-tool-calls">Parsing Tool Calls</a></li>
<li><a class="reference internal" href="#structured-json-output">Structured/JSON Output</a></li>
<li><a class="reference internal" href="#serving-quantized-models">Serving Quantized models</a></li>
<li><a class="reference internal" href="#context-length">Context Length</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    </body>
</html>