{"_id":"650f0710b63668f448157b64","id":"openbmb/UltraFeedback","author":"openbmb","sha":"40b436560ca83a8dba36114c22ab3c66e43f6d5e","lastModified":"2023-12-29T14:11:19.000Z","private":false,"gated":false,"disabled":false,"tags":["task_categories:text-generation","language:en","license:mit","size_categories:10K<n<100K","format:json","modality:text","library:datasets","library:dask","library:mlcroissant","library:polars","arxiv:2310.01377","region:us"],"description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nGitHub Repo\nUltraRM-13b\nUltraCM-13b\n\nUltraFeedback is a large-scale, fine-grained, diverse preference dataset, used for training powerful reward models and critic models. We collect about 64k prompts from diverse resources (including UltraChat, ShareGPT, Evol-Instruct, TruthfulQA, FalseQA, and FLAN). We then use these prompts to query multiple LLMs (see Table for model lists) and generate 4 different responses for each prompt, resulting in a total of 256k samples. \nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openbmb/UltraFeedback.","downloads":1862,"likes":380,"cardData":{"license":"mit","task_categories":["text-generation"],"language":["en"],"size_categories":["100K<n<1M"]},"siblings":[{"rfilename":".gitattributes"},{"rfilename":"README.md"},{"rfilename":"evol_instruct.jsonl"},{"rfilename":"false_qa.jsonl"},{"rfilename":"flan.jsonl"},{"rfilename":"sharegpt.jsonl"},{"rfilename":"truthful_qa.jsonl"},{"rfilename":"ultrachat.jsonl"}],"createdAt":"2023-09-23T15:41:04.000Z","usedStorage":20766353570}