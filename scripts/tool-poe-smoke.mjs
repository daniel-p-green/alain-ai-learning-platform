import 'dotenv/config';
import { ALAINKit } from '../packages/alain-kit/dist/validation/integration.js';

process.env.ALAIN_TOOL_ORCHESTRATOR = '1';
process.env.ALAIN_TOOL_RUNTIME = process.env.ALAIN_TOOL_RUNTIME || 'stub';
process.env.ALAIN_TOOL_MODEL = process.env.ALAIN_TOOL_MODEL || 'poe-tool';

// Allow tests to point at Poe while stubbing outbound requests.
const outlineSteps = Array.from({ length: 6 }, (_, idx) => ({
  step: idx + 1,
  title: `Step ${idx + 1}: Deep dive into topic ${idx + 1}`,
  type: idx === 0 ? 'setup' : idx === 5 ? 'exercise' : 'concept',
  estimated_tokens: 650 + idx * 20,
  content_type: 'markdown'
}));

const mockOutline = {
  title: 'Poe Tool Orchestrator Smoke Outline',
  overview: 'This outline is generated by a stubbed Poe completion to validate the tool orchestrator path end-to-end. '
    + 'It mirrors the required schema used in production, calls out every major deliverable, and describes how learners transition through '
    + 'each deterministic stage of the notebook pipeline so downstream validators receive fully contextualized artifacts.',
  objectives: [
    'Explain the overall workflow for ALAIN tool calling.',
    'Demonstrate a stubbed Poe response flowing through the pipeline.',
    'Validate notebook assembly and QA expectations.'
  ],
  prerequisites: ['Python 3.9+', 'Basic machine learning knowledge'],
  setup: {
    requirements: ['Python 3.9+', 'pip >=23.0'],
    environment: ['Colab', 'Local Jupyter'],
    commands: ['%pip install alain-kit-sdk']
  },
  outline: outlineSteps,
  exercises: [
    {
      title: 'Notebook validation checklist',
      difficulty: 'beginner',
      estimated_tokens: 220
    }
  ],
  assessments: Array.from({ length: 4 }, (_, idx) => ({
    question: `Checkpoint ${idx + 1}: confirm lesson understanding` ,
    options: ['Option A', 'Option B', 'Option C', 'Option D'],
    correct_index: 0,
    explanation: 'Review the generated section content to confirm the correct answer.'
  })),
  summary: 'Learners walk through the ALAIN notebook pipeline, observe telemetry, and prepare the manual for validation. '
    + 'They instrument Harmony sessions, confirm QA gates, reconcile semantic feedback, and ensure export artifacts remain audit ready.',
  next_steps: 'Export the notebook, run full validations, capture Harmony session logs, and publish to the internal catalog.',
  references: ['https://example.com/tool-calling', 'https://example.com/harmony-runtime'],
  estimated_total_tokens: 3200,
  target_reading_time: '24 minutes'
};

function buildSectionPayload(sectionNumber) {
  const paragraph = 'During this stage you execute the orchestrator while Harmony logs each tool invocation. '
    + 'Inspect the generated telemetry to verify that notebook and validator tools report successful outcomes, capture the '
    + 'sequence of tool calls, and note any discrepancies between outline expectations and generated content. '
    + 'Document anomalies so they can be replayed using saved checkpoints and prepare remediation guidance for reviewers. ';
  const markdownBody = `## Step ${sectionNumber}: Execute pipeline instrumentation\n\n`
    + Array.from({ length: 12 }, () => paragraph).join('\n\n');

  const codeBody = [
    'from alain_kit.runtime import telemetry',
    `session = telemetry.load("session-${sectionNumber}")`,
    'print("Captured tools:", [entry["tool"] for entry in session["invocations"]])'
  ].join('\n');

  return {
    section_number: sectionNumber,
    title: `Step ${sectionNumber}: Instrument the run`,
    content: [
      { cell_type: 'markdown', source: markdownBody },
      { cell_type: 'code', source: codeBody }
    ],
    callouts: [
      { type: 'tip', message: 'Tip: Save Harmony session logs alongside validation artifacts for audits.' },
      { type: 'warning', message: 'Warning: Confirm API keys are scoped to read-only environments before sharing logs.' },
      { type: 'note', message: 'Note: You can replay specific sections using the stored checkpoints in /tmp.' }
    ],
    estimated_tokens: 980,
    prerequisites_check: ['Confirm outline objectives have been reviewed.'],
    next_section_hint: 'Prepare to synthesize validator findings in the next step.'
  };
}

const shouldStub = !['false', '0', 'off'].includes((process.env.POE_SMOKE_STUB || '').toLowerCase());

if (shouldStub) {
  let fetchCall = 0;
  globalThis.fetch = async function mockFetch(_url, _options) {
    fetchCall += 1;
    const isOutlineCall = fetchCall === 1;
    const payload = isOutlineCall
      ? mockOutline
      : buildSectionPayload(fetchCall - 1);

    return {
      ok: true,
      status: 200,
      async json() {
        return {
          id: `mock-response-${fetchCall}`,
          choices: [
            {
              index: 0,
              message: {
                role: 'assistant',
                content: JSON.stringify(payload)
              }
            }
          ]
        };
      }
    };
  };
}

async function runSmoke() {
  const kit = new ALAINKit({ baseUrl: 'https://api.poe.com' });
  const result = await kit.generateNotebook({
    modelReference: 'poe/gpt-oss-20b',
    apiKey: process.env.POE_API_KEY || 'stub-poe-key',
    difficulty: 'beginner',
    maxSections: 2,
    customPrompt: {
      title: 'Tool Orchestrator Smoke Test',
      context: 'Verify that stubbed Poe responses flow through the Harmony runtime.'
    }
  });

  const sections = result.sections?.length || 0;
  const label = sections === 2 ? 'PASS' : 'FAIL';
  console.log(`[tool-poe-smoke] ${label}: generated ${sections} sections, quality=${result.qualityScore}`);
  console.log(`[tool-poe-smoke] QA status: ${result.qaReport.overall_status}, Colab compatible: ${result.colabValidation.isCompatible}`);
}

runSmoke().catch((err) => {
  console.error('[tool-poe-smoke] ERROR', err);
  process.exitCode = 1;
});
